{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Parser for Structured MJP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parser works specifically with the Modernist Journals Project. Some of the magazines have more markup, specifically with genres in each issues encoded. This parser captures genre information, such as text that has been encoded as poetry, fiction, articles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from xml.dom.minidom import parseString\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_path = \"/Users/williamquinn/Desktop/DH/Python/MJP/Output/catalog_file_7-15-2019.txt\"\n",
    "text_path = \"/Users/williamquinn/Desktop/DH/Python/MJP/Output/text_file_7-15-2019.txt\"\n",
    "mods_path = \"/Users/williamquinn/Desktop/DH/Python/MJP/Output/mods_file_7-15-2019.txt\"\n",
    "mods_catalog = \"/Users/williamquinn/Desktop/DH/Python/MJP/Output/mods_cat_file.txt\"\n",
    "\n",
    "list_of_files = glob.glob(\"/Users/williamquinn/Desktop/DH/R/Magazines/All_Magazines/*.xml\")\n",
    "list_of_mods = glob.glob(\"/Users/williamquinn/Desktop/DH/R/Magazines/All_MODS/*/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(article):\n",
    "    for pargroup in dom.getElementsByTagName(\"title\"):\n",
    "        return pargroup.firstChild.data\n",
    "    \n",
    "def what_type(article):\n",
    "    try:\n",
    "        return article.getAttribute(\"type\")\n",
    "    except IndexError:\n",
    "        raise\n",
    "        return \"unknown\"\n",
    "    \n",
    "def what_id(dom):\n",
    "    for element in dom.getElementsByTagName(\"TEI\"):\n",
    "        return element.getAttribute(\"xml:id\")\n",
    "    \n",
    "def full_text(article):\n",
    "    paragraph_list = []\n",
    "    for pargroup in article.getElementsByTagName(\"ab\"):\n",
    "        try:\n",
    "            paragraph = pargroup.firstChild.data\n",
    "        except AttributeError:\n",
    "            return \"NO <AB>\"\n",
    "\n",
    "        paragraph = paragraph.replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
    "        paragraph_list.append(paragraph)\n",
    "        \n",
    "    return \" \".join(paragraph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 462 ms, total: 11.2 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# write to text_file and catalog_file\n",
    "n = 0\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "with open(catalog_path, \"w+\") as catalog_file, open(text_path, \"w+\") as text_file:\n",
    "\n",
    "    catalog_file.write(\"id\" + \"\\t\" + \"mjp_id\" + \"\\t\" + \"magazine\" + \"\\t\" + \"type\" + \"\\n\")\n",
    "    text_file.write(\"id\" + '\\t' + \"mjp_id\" + \"\\t\" + \"text\" + \"\\n\")\n",
    "\n",
    "    for file_name in list_of_files:\n",
    "        FI = open(file_name, \"r\")\n",
    "        data = FI.read()\n",
    "        FI.close()\n",
    "        dom = parseString(data)\n",
    "        ID = what_id(dom)\n",
    "        issues = dom.getElementsByTagName(\"div\")\n",
    "        for issue in issues:\n",
    "            articles = issue.getElementsByTagName(\"div\")\n",
    "            for article in articles:\n",
    "                n = n + 1\n",
    "                atype = what_type(article)\n",
    "                text = full_text(article)\n",
    "                magazine = title(article)\n",
    "                catalog_file.write(str(n) + \"\\t\" + ID + \"\\t\" + magazine + \"\\t\" + atype + \"\\n\")\n",
    "                text_file.write(str(n) + \"\\t\" + ID + \"\\t\" + text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "catalog_df = pd.read_csv(\"/Users/williamquinn/Desktop/DH/Python/MJP/Output/catalog_file_7-15-2019.txt\", \\\n",
    "                 sep=\"\\t\")\n",
    "\n",
    "catalog_df[\"magazine\"] = catalog_df[\"magazine\"].str.lower() \\\n",
    "    .str.replace(r\"(the masses).*\",\"\\g<1>\", regex=True) \\\n",
    "    .str.replace(r\"the seven arts.*\",\"the seven arts\", regex=True) \\\n",
    "    .str.replace(r\"the freewoman.*\",\"marsden magazines\", regex=True) \\\n",
    "    .str.replace(r\"the new freewoman.*\",\"marsden magazines\", regex=True) \\\n",
    "    .str.replace(r\"the egoist.*\",\"marsden magazines\", regex=True) \\\n",
    "    .str.replace(r\"others[t]\",\"others\", regex=True) \\\n",
    "    .str.replace(r\"the liitle review\",\"the little review\", regex=True)\n",
    "\n",
    "catalog_df[\"type\"] = catalog_df[\"type\"].str.lower() \\\n",
    "    .str.replace(r\"ar[^v].*\",\"articles\", regex=True) \\\n",
    "    .str.replace(r\"a[drv][^rit].*\",\"advertisements\", regex=True) \\\n",
    "    .str.replace(r\"poems\",\"poetry\", regex=True) \\\n",
    "    .str.replace(r\"fic[tion].*\",\"fiction\", regex=True) \\\n",
    "    .str.replace(r\"im.*\",\"images\", regex=True) \\\n",
    "    .str.replace(r\"fro.*\", \"front\", regex=True) \\\n",
    "    .str.replace(r\"con.*\", \"content\", regex=True)\n",
    "\n",
    "text_df = pd.read_csv(\"/Users/williamquinn/Desktop/DH/Python/MJP/Output/text_file_7-15-2019.txt\", \\\n",
    "                 sep=\"\\t\")\n",
    "\n",
    "text_df[\"text\"] = text_df[\"text\"].astype(str) \\\n",
    "    .str.lower() \\\n",
    "    .str.strip() \\\n",
    "    .str.replace(r'[^\\w\\s]','', regex=True) \\\n",
    "    .str.replace(r\"pgbrk\",\"\", regex=True) \\\n",
    "    .str.replace('\\.0', '', regex=True)\n",
    "    \n",
    "\n",
    "mods_df = pd.read_csv(\"/Users/williamquinn/Desktop/DH/Python/MJP/Output/mods_file_7-15-2019.txt\", \\\n",
    "                     sep=\"\\t\")\n",
    "\n",
    "catalog_df = pd.merge(catalog_df, mods_df, on=\"mjp_id\")\n",
    "mjp_df = pd.merge(catalog_df, text_df, on='id')\n",
    "\n",
    "\n",
    "mjp_df = mjp_df[[\"id\", \"magazine\", \"type\", \"text\", \"date\"]]\n",
    "\n",
    "mjp_df = mjp_df.loc[mjp_df[\"type\"] != \"images\"]\n",
    "\n",
    "mjp_df = mjp_df.rename(columns={\"id\": \"mjp_id\"})\n",
    "\n",
    "mjp_df.to_csv(\"/Users/williamquinn/Desktop/DH/Python/MJP/Output/mjp_documents.txt\", \n",
    "              sep='\\t', \n",
    "             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Version Below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.428166\n"
     ]
    }
   ],
   "source": [
    "# write to mods_file\n",
    "startTime = datetime.now()\n",
    "\n",
    "def get_date(tree):\n",
    "    for elem in tree.findall(\".//ns:dateIssued\", namespaces=ns):\n",
    "        return elem.text\n",
    "    \n",
    "with open(mods_path, \"w\") as mods_data:\n",
    "    mods_data.write(\"file\" + \"\\t\" + \"mjp_id\" + \"\\t\" + \"date\" + \"\\n\")\n",
    "    \n",
    "    for file in list_of_mods:\n",
    "        refile = re.search(r'.*/(.*)_mods.xml', str(file)).group(1)\n",
    "        read = open(file, \"rt\")\n",
    "        tree = ET.parse(read)\n",
    "        namespace = re.search(r\".*{(.*)}.*\", tree.getroot().tag)\n",
    "        ns = {\"ns\":namespace.group(1)}\n",
    "\n",
    "        mods_id = tree.getroot().attrib.get('ID')\n",
    "        date = get_date(tree)\n",
    "        \n",
    "        mods_data.write(refile + '\\t' + mods_id + '\\t' + date + '\\n')\n",
    "    \n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "        \n",
    "def get_date(tree_str):\n",
    "    for elem in tree_str.findall(\".//ns:dateIssued\", namespaces=ns):\n",
    "        dateText = elem.text\n",
    "        return dateText\n",
    "    \n",
    "def get_title(tree_str):\n",
    "    for rItem in tree_str.findall(\".//ns:title\", namespaces=ns):\n",
    "        title_Text = rItem.text\n",
    "        return title_Text\n",
    "        \n",
    "def get_name(tree_str):\n",
    "    for rItem in tree_str.findall(\".//ns:name[@type='personal']/ns:namePart\", namespaces=ns):\n",
    "        name_Text = rItem.text\n",
    "        return name_Text\n",
    "\n",
    "\n",
    "with open(mods_catalog, \"w\") as modCat:\n",
    "    modCat.write(\"mjp_id\" + \"\\t\" + \"date\" + \"\\t\" + \"name\" + \"\\t\" + \"title\" + \"\\n\")\n",
    "    \n",
    "    for file in list_of_mods:\n",
    "        refile = re.search(r'.*/(.*)_mods.xml', str(file)).group(1)\n",
    "        read = open(file, \"rt\")\n",
    "        tree = ET.parse(read)\n",
    "        \n",
    "        namespace = re.search(r\".*{(.*)}.*\", tree.getroot().tag)\n",
    "        ns = {\"ns\":namespace.group(1)}\n",
    "        mods_id = tree.getroot().attrib.get('ID')\n",
    "        date = get_date(tree)\n",
    "        \n",
    "        for rItem in tree.findall(\".//ns:relatedItem[@type='constituent']\", namespaces=ns):\n",
    "            name = get_name(rItem)\n",
    "            title = get_title(rItem)\n",
    "            modCat.write(str(mods_id) + '\\t' + date + '\\t' + str(name) + '\\t'+ str(title) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate number of words in MJP: 12031577\n",
      "0:00:03.050859\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "mjp_count = 0\n",
    "\n",
    "with open(text_path, \"r\") as text:\n",
    "    for w in text.read().split():\n",
    "        mjp_count = mjp_count + 1\n",
    "\n",
    "print (\"Approximate number of words in MJP:\", mjp_count-8981) # 8981 is the number of id's printed with each text block\n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:15.723533\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# write from xml with etree if necessary\n",
    "\n",
    "\n",
    "def get_magazine(tree_str):\n",
    "    try:\n",
    "        title = tree_str.find(\".//ns:teiHeader//ns:title\", namespaces=ns)\n",
    "        clean_title = re.sub(\"[^A-z ]\", \"\", title.text)\n",
    "        return (clean_title)\n",
    "    except AttributeError:\n",
    "        print (file_name)\n",
    "        raise\n",
    "    \n",
    "def get_type(tree_str):\n",
    "    try:\n",
    "        return tree_str.get(\"type\")\n",
    "    except IndexError:\n",
    "        raise\n",
    "        return \"unknown\"\n",
    "        \n",
    "def get_text(tree_str):\n",
    "    group_content = []\n",
    "    for group in tree_str.findall('.//ns:ab', namespaces=ns):\n",
    "        content_l = group.itertext()\n",
    "        content = ' '.join(str(w) for w in content_l).replace('\\t','').replace('\\n','').lower()\n",
    "        content_clean = re.sub(\" +\", \" \", content)\n",
    "        group_content.append(content_clean)\n",
    "    return (\" \".join(str(w) for w in group_content))\n",
    "\n",
    "\n",
    "with open(catalog_path, \"w\") as catalog_file, open(text_path, \"w\") as text_file:\n",
    "    n = 0\n",
    "\n",
    "    catalog_file.write(\"id\" + \"\\t\" + \"mjp_id\" + \"\\t\" + \"magazine\" + \"\\t\" + \"type\" + \"\\n\")\n",
    "    text_file.write(\"id\" + '\\t' + \"mjp_id\" + \"\\t\" + \"text\" + \"\\n\")\n",
    "\n",
    "    for file_name in list_of_files:\n",
    "        file = open(file_name, 'rt')\n",
    "        tree = ET.parse(file)\n",
    "        try:\n",
    "            namespace = re.search(r\".*{(.*)}.*\", tree.getroot().tag)\n",
    "            ns = {\"ns\":namespace.group(1)}\n",
    "        except:\n",
    "            xml_id = tree.findall('ns:TEI', namespaces=ns)\n",
    "            \n",
    "        file.close()\n",
    "        \n",
    "\n",
    "        magazine = get_magazine(tree)\n",
    "        mods_id = tree.getroot().attrib.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "\n",
    "\n",
    "        for entry in tree.findall(\".//ns:div[@type='issue']//ns:div\", namespaces=ns):\n",
    "            etype = get_type(entry)\n",
    "            text = get_text(entry)\n",
    "            n = n + 1\n",
    "            catalog_file.write(str(n) + \"\\t\" + mods_id + \"\\t\" + magazine + \"\\t\" + etype + \"\\n\")\n",
    "            text_file.write(str(n) + \"\\t\" + mods_id + \"\\t\" + text + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print (datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
